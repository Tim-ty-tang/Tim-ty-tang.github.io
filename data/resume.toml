# Resume
[profile]        
    enable = true
    name = "Tsz Yu Timothy Tang"
    tagline = "Senior AI Engineer | Machine Learning Engineer | Data Scientist"
    avatar = ""

[contact]
    enable = true
    location = "London | Hong Kong"

    [[contact.list]]
        icon = "fas fa-phone-square"
        url = "tel:#"
        text = "+447887930652 | +85255897743"
    [[contact.list]]
        icon = "fas fa-envelope-square"
        url = "mailto:#"
        text = "tangtszyu5d@gmail.com"
    [[contact.list]]
        icon = "fas fa-globe"
        url = "ttyt.me"
        text = "ttyt.me"

[summary]
    enable = true
    text = """
Machine Learning Engineer and Data Scientist. With a focus on the scientific computing python stack and associated low level language access (C via Cython, CUDA via Pytorch). 

Extensive hands-on experience with production LLM systems and LLMOps. Expert in cutting-edge LLM frameworks, particularly LangGraph for building stateful multi-agent systems and complex conversational workflows. Proficient in DSPy for programmatic prompt optimization. 

Deep expertise in customizing, fine-tuning, deploying, and systematically evaluating both open-source and proprietary LLMs for production use cases. Experienced in model adaptation techniques including fine-tuning, prompt optimization, and domain-specific model customization.

Specialized in LLM observability and evaluation infrastructure. Proficient in distributed tracing frameworks (OpenTelemetry) for LLM applications, building comprehensive evaluation pipelines, and establishing monitoring systems for production AI. 

Experienced in designing and implementing guardrails, safety systems, and quality scoring mechanisms for conversational AI.

Also experienced in distributed computing for data science processes. (pyspark, dask). 

Used Cloud tools for machine learning (Azure ML, Databricks, Palantir Foundry)

Experienced in web frameworks (Flask, Fastapi, torchserve) for model and algorithm deployment and serving. 

Experienced in Spark via PySpark, and various data engineering tools (Kafka, Airflow, DuckDB) for batch processes and distributed training. AWS and Azure experience (S3, Redshift, Glue, Azure Actions, Blob Storage). 

Experienced in managing tooling for the Python Data Science Stack (uv, Poetry, Conda)

Well versed in up to date Python modeling packages (XGBoost, LightGBM, StatsModel) and deep learning (Pytorch). Experienced in open source LLMs deployment (Ollama) and LLM evaluations (Deepeval, InspectAI).
    """


[skills]
    enable = true

    [[skills.list]]
    title = "Technical"
        [[skills.list.items]]
            details = "Languages: Python // SQL // Matlab"
        [[skills.list.items]]
            details = "Lower Level: C via Cython // JAX"
        [[skills.list.items]]
            details = "MLOps: Flask // Fastapi // torchserve // MLFlow // Dask"
        [[skills.list.items]]
            details = "Data Engineering: Kafka // Airflow // DuckDB // Spark // PostgreSQL"
        [[skills.list.items]]
            details = "AI Agents: LangGraph // DSPy // PydanticAI // SmolAgents // ClaudeCode SDK"
        [[skills.list.items]]
            details = "LLM Tooling: Weaviate // Unsloth // LoRA // QLoRA // FAISS"
        [[skills.list.items]]
            details = "Modelling: XGBoost // LightGBM // StatsModel // Pytorch"
        [[skills.list.items]]
            details = "LLMOps: vLLM // llama.cpp // deepeval // evals // Langfuse // OpenTelemetry"
        [[skills.list.items]]
            details = "AWS (S3, Redshift, Glue, EC2)"
        [[skills.list.items]]
            details = "Azure (Azure Actions, Blob Storage, AzureML)"
        [[skills.list.items]]
            details = "Databricks // Palantir"

    [[skills.list]]
    title = "Industries"
        [[skills.list.items]]
        details = "Online Retail & Search"
        [[skills.list.items]]
        details = "Logistics"
        [[skills.list.items]]
        details = "Renewables"
        [[skills.list.items]]
        details = "Insurance"
        [[skills.list.items]]
        details = "Oil aand Gas"
        [[skills.list.items]]
        details = "Consulting"

    [[skills.list]]
    title = "Other"
        [[skills.list.items]]
        details = "Interested in using: Rust/Julia/Dagster/CUDA"
        [[skills.list.items]]
        details = "Topics of Interest: Knowledge Gaph in LLM/Event-baased Time Series Modelling/Alternative Market Making"

[education]
enable = true

[[education.list]]
degree = "MSc in Data Science"
university = "Kings College London"
dates = "2017 - 2018"
[[education.list]]
degree = "Msci in Maths and Physics"
university = "University College London"
dates = "2010 - 2014"

[awards]
enable = false

[[awards.list]]
name = "Award Lorem Ipsum"
body = "Microsoft lorem ipsum"
date = "2019"

[languages]
enable = true

[[languages.list]]
name = "English"
level = "Native"
[[languages.list]]
name = "Chinese (Mandarin)"
level = "Native"
[[languages.list]]
name = "Chinese (Cantonese)"
level = "Native"


[interests]
enable = true

[[interests.list]]
name = "Sport Analytics"
[[interests.list]]
name = "Scuba"
[[interests.list]]
name = "Photography"
[[interests.list]]
name = "Tennis"
[[interests.list]]
name = "TCG"

[experience]
enable = true


[[experience.list]]
title = "AI ML Engineering Technical Team Lead"
dates = "April 2025"
company = "Rezolve AI"
details = """
As an AI ML Engineer Team Lead, led a team of AI Engineers in developing and operationalizing LLM-based conversational AI systems for retail applications. Established comprehensive LLMOps practices including evaluation frameworks, observability infrastructure, and safety systems for production AI.

Technical team lead for preview releases, managing 4-5 engineers while contributing hands-on to architectural design and implementation. Core work involves advancing multi-agent conversational systems for retail applications.

* Led the transition from static workflow-based systems to dynamic tool-based and subagent-based architectures with background context update functionalities.
* Coordinated development across core technical areas including context management and compacting, prompt optimization, agent-to-agent (A2A) communication protocols, and streaming response implementations.

Established LLMOps best practices for evaluation and observability, influencing organization-wide adoption. Core work involves building comprehensive evaluation and monitoring infrastructure for production LLM systems.

* Designed comprehensive evaluation framework tying together offline evals for engineering improvement with online CI/CD evaluation pipelines.
* Developed proprietary testing library with scenario-based conversation generation for multi-agent systems.
* Architected distributed tracing infrastructure for LLM applications, establishing standards for performance monitoring and analytics across teams.

Designed and implemented guardrail systems, scoring mechanisms, and intent classification systems to ensure safe, high-quality conversational experiences.

Partnered with external vendors on integration initiatives and facilitated knowledge sharing through pair programming and onboarding support.
"""

[[experience.list]]
title = "Data Scientist (Contractor) with Machine Learning Engineering Focus"
dates = "March 2022 - December 2024"
company = "BP"
details = """
As a data science contractor, provided Data Science product expertise and analysis to various functions across BP. This included Production, Refining, Renewables, Strategy and Safety. 

Deeply involved as a product data scientist in product development for a renewables modelling platform. Core work involves researching and designing countermeasures against the risks regarding Model IP in the context of an API Marketplace.

* Investigated the effects and risks of model theft and replication if a model is made available in a models marketplace. With a family of internal test models, tested the limits of reverse engineering under a couple of scenarios defined through customer research.
* Model IP protection: With the above results, designed a framework to measure the relative risk of theft and replication for a given model.  Using the resulting metrics, a further system is developed to capture the ongoing risks of model calls on the API marketplace. This was turned into a monitoring and alerting service in production with the architecture and software engineering teams.
* Investigated various GenAI applications in the context of a models marketplace. Generally focused on creating POCs and examples for RAG and GenAI based retrieval for various model documentation.
* For the above designs, worked with internal counsel to submit for patent application.
* Model marketplace development: As part of business development of the platform, aided in consulting for internal teams and startups on the strategy of productionizing and monetizing their internal models. 

Working in conjunction with compressor engineers, introduced and applied explainable machine learning to compressor fouling analysis:

- Working with compressor engineers to find factors for analysis. Further feature engineering was done to further analyze potential fouling issues in the compressors. 
- Created a model with explainable machine learning to explore counterfactuals. Designed a dashboard based on the model to allow compressor engineers to explore a angle of scenarios and options.

Analysis and modeling of equipment failures. Produced a survival analysis model to provide a clearer view of the pattern of failures.

Involved in introducing statistical analysis to understanding pattern of survival analysis, and aid in setting better health and safety targets.  

Consulting work with strategy, aiding the team in designing the roadmap for modernizing data stacks and tooling.

Investigated Microsoft and OpenAI machine learning API offerings as part of a team wide AI drive. Focused especially on producing internal benchmarks using various evaluations packages.

As a member of technical staff, participated in facilitating knowledge sharing and mentorship.  Organized and led a team data science reading group.
"""

[[experience.list]]
title = "Machine Learning Engineer"
dates = "August 2018 - March 2022"
company = "Aioi Nissay Dowa"
details = """
With a focus on vehicle telematics data and insurance customers, worked on providing classification, categorisation and scoring models to enable paradigm changes and automation in insurance operations. Was involved in the full machine learning models development and deployment cycle, which includes, exploratory data analysis, data collection, feature engineering, model building and optimisation, acceptance testing, API building, deployment/serving and continuous monitoring/training.

Project lead for driving behaviour algorithms. Lead a team of 2-3 data scientists and engineers to develop the product.

* Involved in creating new generations of driving behaviour predictive models in association with team data scientists and insurance analysts. Using mainly telematics data and incorporating other data sources, such as mapping and weather information,   
* The team was able to increase the ability to identify 70% more customers that have a high risk of causing an insurance event or impact incident compared to the previous telematics method. This translates to an estimated gain in loss prevention ratio of 30%.  
* The team was able to create a machine learning scoring pipeline in production to handle more than 100k drivers, which translates to over 200k trips a day.  
* Supported the transition to a next generation platform in conjunction with the engineering teams, with a focus on Data-as-a-service model.

Contributed to crash identification algorithms via telematics dynamics.

* Created a filtering algorithm to identify noisey crashes, to either enable cleaning or removal from sample. We produced a capture rate of 95% of all real crashes, reducing the number of crashes that require customer support intervention by half.  
* Involved in designing further downstream categorisation and automation systems to enable automatic customer services and incident triage via a customer portal.

Delivered MLOps practises in conjunction with Operations teams

* Created the CI/CD workflow for python and specifically machine learning projects. Created a bespoke deployment framework in conjunction with operations to address team needs. Furthermore, defined and built required data pipelines to deliver continuous monitoring and analysis of the predictive and classification models.

Delivered an end-to-end framework for model explainability, in order to enable insurance product enhancements and better customer service on the platform.

Involved in generating required visualisation and dashboard for management to understand data. Also supported any ad-hoc analysis and reporting for clients.

Involved in product, architecture and resource planning for projects. Managed team of 2 junior machine learning engineers to deliver projects, with coaching and guidance provided.
"""

[[experience.list]]
title = "Operational Data Analyst"
dates = "October 2016 - September 2017"
company = "Amazon"
details = """
Maintain and manage performance metrics and communications for logistic operations with data-driven. Drove innovation in reporting and metrics management process.

* Contact with key stakeholders to ensure compliance and improve performance of linehauls and warehouse operations.  
* Automation of reporting and communication process with VBA, SQL and Microsoft stack of business analytics tools.  
* Further developed warehouse operational metrics in tandem with operations management to identify areas of improvement.
"""

[[experience.list]]
title = "Analyst"
dates = "October 2014 - March 2016"
company = "KPMG"
details = """
* Technology risk consulting  
* Projects include: IT audit, IT process review, due diligence reporting, ISAE3402 reporting, Data quality assurance, information governance review.  
* Participated in designing audit programmes for bespoke projects.  
* Participated in dashboard building and analysis for clients.
"""

[projects]
enable = false

[[projects.list]]
title = "Project Lorem Ipsum"
meta = "Open Source"
tagline = "You can use this section for your side projects. Lorem ipsum dolor sit amet, consectetuer adipiscing elit. Aenean commodo ligula eget dolor. Aenean massa. Cum sociis natoque penatibus et magnis dis parturient montes, nascetur ridiculus mus."

[[projects.list]]
title = "Project Sed Fringilla"
meta = "Open Source"
tagline = "You can use this section for your side projects. Cras dapibus. Vivamus elementum semper nisi. Aenean vulputate eleifend tellus. Aenean leo ligula, porttitor eu, consequat vitae, eleifend ac, enim."

[[projects.list]]
title = "Project Praesent"
meta = "Open Source"
tagline = "You can use this section for your side projects. Cras dapibus. Vivamus elementum semper nisi. Aenean vulputate eleifend tellus. Aenean leo ligula, porttitor eu, consequat vitae, eleifend ac, enim."


[information]
enable = false

[[information.list]]
title = "Papers"
[[information.list.items]]
details = "2018 · Lorem Ipsum"
[[information.list.items]]
details = "2016 · Sed Fringilla"

[[information.list]]
title = "Interests"
details = "Climbing, Snowboarding, Photography, Travelling"

