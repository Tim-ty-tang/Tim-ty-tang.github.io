---
title: "Depth is All You Need part 2"
date: "2025-01-12"
summary: "A short post for the part 2 of LLM depths"
description: "Exploring the depths of LLMs and VLMs"
toc: false
readTime: true
---

This is the second part of my series on the depths of LLMs and VLMs.

This time we are going to look at 3 aggregated sources.

## [Tim Kellog's Primer](https://timkellogg.me/blog/2024/12/19/ai-primer)

A pretty good up-to-date what-to-do primer. Lots of sources that are worth checking out, and i think as a keyword dump, it's very helpful. Following the topics and do-and-do-nots gets you up and running almost immediately. Though in honesty it's a bit handsy and not deep dive enough, but that's what a primer is for.

## [GenAI Handbook](https://genai-handbook.github.io/)

The Handbook on the other hand goes much deeper on what you should learn. IT's almost a sort of META textbook, effectively you can read it, then use the section and links to properly deepdive and learn. What I truly love about this handbook is it does not skip any basics, but goes deep enough down to some optimisation, some inference techniques, some non LLM gen AI architectures and topics. It's just a banger in general.

## [LLM course](https://github.com/mlabonne/llm-course?tab=readme-ov-file)

Much closer to aa roadmap, this gives a lot of code examples and libraries, which is nice. It's much more hands on, and really is a JOB roadmap, but valuable nonetheless.

For the following months, I will be going through this post and the prior post, to really nail down the modern trend of LLM and VLM architectures
